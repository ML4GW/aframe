[tool.pinto]
steps = [
    "datagen:deploy-background",
    "datagen:generate-waveforms",
    "datagen:generate-glitches",
    "datagen:deploy-timeslide-waveforms",
    "train:train:resnet",
    "export:export-model:resnet",
    "infer:deploy-infer",
    "mdc:deploy-mdc",
    "vizapp:vizapp"
]

[tool.typeo.base]
basedir = "${BASE_DIR}"
datadir = "${DATA_DIR}"
accounting_group_user = "${LIGO_USERNAME}"
accounting_group = "${LIGO_GROUP}"
logdir = "${BASE_DIR}/log"
sample_rate = 2048
kernel_length = 1.5
ifos = ['H1', 'L1']
hopeless_snr_thresh = 0

# start/stop times reflect use of
# --start-duration $((24 * 3600 * 10)) flag
# when generating MDC test dataset.
# train_stop is the start of the first segment
# of the generated dataset.
train_start = 1240579783
train_stop = 1241443783  # 10 day train window
test_stop = 1244035783 # 30 day test window

channel = "DCS-CALIB_STRAIN_CLEAN_C01"
frame_type = "HOFT_C01"
state_flag = "DCS-ANALYSIS_READY_C01:1"
resnet = {layers = [3, 4, 6, 3], norm_groups = 16}
repository_directory = "${BASE_DIR}/model_repo/" 
force_generation = false
Tb = 5184000  # 60 days of background
inference_sampling_rate = 16
inference_batch_size = 128
inference_psd_length = 64
training_psd_length = 8

waveform_duration = 4
minimum_frequency = 20
reference_frequency = 50
highpass = 32
training_prior = "aframe.priors.priors.mdc_prior_chirp_distance"
testing_prior = "aframe.priors.priors.mdc_prior_chirp_distance"
fduration = 1
valid_frac = 0.25
cosmology = "aframe.priors.cosmologies.planck"
streams_per_gpu = 3
waveform_approximant = "IMRPhenomPv2"
verbose = true


[tool.typeo.scripts.deploy-background]
datadir = "${base.datadir}"
logdir = "${base.logdir}"
channel = "${base.channel}"
state_flag = "${base.state_flag}"
train_start = "${base.train_start}" 
train_stop = "${base.train_stop}" 
test_stop = "${base.test_stop}"
ifos = "${base.ifos}"
sample_rate = "${base.sample_rate}" 
minimum_train_length = 8000
minimum_test_length = 1024
force_generation = "${base.force_generation}"
accounting_group = "${base.accounting_group}"
accounting_group_user = "${base.accounting_group_user}"

[tool.typeo.scripts.generate-glitches]
snr_thresh = 5
window = 2
start = "${base.glitch_start}"
stop = "${base.train_stop}"
test_stop = "${base.test_stop}"
channel = "${base.channel}"
frame_type = "${base.frame_type}"
state_flag = "${base.state_flag}"
f_min = "${base.highpass}"
q_min = 3.3166
q_max = 108
cluster_dt = 0.5
chunk_duration = 124
segment_duration = 64 
overlap = 4
mismatch_max = 0.2
force_generation = "${base.force_generation}"
ifos = "${base.ifos}"
datadir = "${base.datadir}/train"
logdir = "${base.logdir}"
sample_rate = "${base.sample_rate}"
analyze_testing_set = false
verbose = true

[tool.typeo.scripts.generate-waveforms]
minimum_frequency = "${base.minimum_frequency}" 
reference_frequency = "${base.reference_frequency}"
datadir = "${base.datadir}/train"
logdir = "${base.logdir}"
num_signals = 100000
prior = "${base.training_prior}"
sample_rate = "${base.sample_rate}" 
waveform_duration = "${base.waveform_duration}"
force_generation = "${base.force_generation}"
waveform_approximant = "${base.waveform_approximant}"
cosmology = "${base.cosmology}"

[tool.typeo.scripts.train]
# input and output paths
background_dir = "${base.datadir}/train/background"
waveform_dataset = "${base.datadir}/train/signals.h5"

logdir = "${base.logdir}"
outdir = "${base.basedir}/training"

# optimization args
batch_size = 384
max_epochs = 200
max_lr = 1e-3
lr_ramp_epochs = 9
weight_decay = 0.0

snr_thresh = 4
max_min_snr = 12
max_snr = 100
snr_alpha = 3
snr_decay_steps = 768

# data args
ifos = "${base.ifos}"
sample_rate = "${base.sample_rate}"
kernel_length = "${base.kernel_length}"
fduration = "${base.fduration}"
highpass = "${base.minimum_frequency}"
psd_length = "${base.training_psd_length}"

# augmentation args
trigger_distance = -0.75
waveform_prob = 0.5

swap_frac = 0.025
mute_frac = 0.12

# validation args
valid_frac = "${base.valid_frac}"
valid_stride = 0.5
max_fpr = 1e-3
valid_livetime = 57600  # 16 hours of background
early_stop = 200
checkpoint_every = 3

# misc args
device = "cuda"
profile = false
use_amp = true

# arch parameters
commands.resnet = "${base.resnet}"

[tool.typeo.scripts.export-model]
# paths
repository_directory = "${base.repository_directory}" 
outdir = "${base.logdir}"
weights = "${base.basedir}/training/weights.pt"

# input-output mapping info
num_ifos = 2 
inference_sampling_rate = "${base.inference_sampling_rate}"
sample_rate = "${base.sample_rate}"
kernel_length = "${base.kernel_length}"
batch_size = "${base.inference_batch_size}"
fduration = "${base.fduration}"
highpass = "${base.highpass}"
fftlength = 8
psd_length = "${base.inference_psd_length}"

# repo/triton parameters
aframe_instances = 6
streams_per_gpu = "${base.streams_per_gpu}"
platform = "tensorrt_plan"
verbose = false
clean = true

# arch parameters
commands.resnet = "${base.resnet}"

[tool.typeo.scripts.deploy-timeslide-waveforms]
# paths and what not
outdir = "${base.basedir}"
datadir = "${base.datadir}"
logdir = "${base.logdir}"
accounting_group = "${base.accounting_group}"
accounting_group_user = "${base.accounting_group_user}"

# background parameters
start = "${base.train_stop}"
stop = "${base.test_stop}"
psd_length = "${base.inference_psd_length}"
sample_rate = "${base.sample_rate}"
ifos = "${base.ifos}"
state_flag = "${base.state_flag}"
min_segment_length = 1024

# timeslide parameters
shifts = [0, 1]
Tb = "${base.Tb}"

# injection parameters
prior = "${base.testing_prior}"
minimum_frequency = "${base.minimum_frequency}"
reference_frequency = "${base.reference_frequency}"
highpass = "${base.highpass}"
spacing = 48
buffer = 16
cosmology = "${base.cosmology}"
snr_threshold = 0 
waveform_duration = "${base.waveform_duration}"
waveform_approximant = "${base.waveform_approximant}"

[tool.typeo.scripts.deploy-infer]
# paths
model_repo_dir = "${base.repository_directory}"
data_dir = "${base.datadir}/test/background"
injection_set_file = "${base.datadir}/test/waveforms.h5"
output_dir = "${base.basedir}/infer"
log_dir = "${base.logdir}"

# condor args
accounting_group_user = "${base.accounting_group_user}"
accounting_group = "${base.accounting_group}"

# triton args
model_name = "aframe-stream"
model_version = -1
image = "hermes/tritonserver:22.12"
sequence_id = 1001

# timeslide args
Tb = "${base.Tb}"
shifts = [0, 1]
throughput = 320

# data args
sample_rate = "${base.sample_rate}"
inference_sampling_rate = "${base.inference_sampling_rate}"
batch_size = "${base.inference_batch_size}"
ifos = "${base.ifos}"
chunk_size = 4096

# analysis args
integration_window_length = 1
cluster_window_length = 8
fduration = "${base.fduration}"
psd_length = "${base.inference_psd_length}"

# misc
verbose = "${base.verbose}"


[tool.typeo.scripts.deploy-mdc]
# paths
model_repo_dir = "${base.repository_directory}"
data_dir = "${base.datadir}"
output_dir = "${base.basedir}/mdc"
log_dir = "${base.logdir}"

# condor args
accounting_group_user = "${base.accounting_group_user}"
accounting_group = "${base.accounting_group}"

# triton args
model_name = "aframe-stream"
model_version = -1
image = "hermes/tritonserver:22.12"
sequence_id = 1001

# timeslide args
Tb = "${base.Tb}"
throughput = 100

# data args
sample_rate = "${base.sample_rate}"
inference_sampling_rate = "${base.inference_sampling_rate}"
batch_size = "${base.inference_batch_size}"
ifos = "${base.ifos}"
chunk_size = 4096

# analysis args
integration_window_length = 1
cluster_window_length = 8
fduration = "${base.fduration}"

# misc
verbose = "${base.verbose}"


[tool.typeo.scripts.analyze]
data_dir = "${base.basedir}/timeslide_injections/"
write_dir = "${base.basedir}/timeslide_injections/"
results_dir = "${base.basedir}/results/" 
window_length = 1.0
norm_seconds = [0, 10, 100, 1000]
t_clust = 5
max_tb = 604800
force = false
log_file = "${base.logdir}/analyze.log"
verbose = false

[tool.typeo.scripts.vizapp]
source_prior = "${base.testing_prior}"
timeslides_results_dir = "${base.basedir}/timeslide_injections/"
timeslides_strain_dir = "${base.datadir}/timeslide_injections"
ifos = "${base.ifos}"
start = "${base.train_stop}"
stop = "${base.test_stop}"
veto_definer_file = "./vetoes/H1L1-HOFT_C01_O3_CBC.xml"
gate_paths = {"H1" = "./vetoes/H1-O3_GATES_1238166018-31197600.txt" , "L1" = "./vetoes/L1-O3_GATES_1238166018-31197600.txt"}
train_data_dir = "${base.datadir}"
sample_rate = "${base.sample_rate}"
fduration = "${base.fduration}"
valid_frac = "${base.valid_frac}"
logdir = "${base.basedir}"
cosmology = "${base.cosmology}"
verbose = true
