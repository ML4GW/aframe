# luigi level config
[luigi_core]
local_scheduler = true
module = aframe
log_level = INFO

# configuration for pipeline parameters

[luigi_base]
ifos = ["H1", "L1"]

# data generation parameters
train_start = 1250900000
train_stop = 1250909263
test_stop = 1251109263 
max_duration = 20000
Tb = 2592000
flag = DATA 
channels =  &::ifos
shifts = [0, 1]
seed = 1122

streams_per_gpu = 6

# waveform parameters
waveform_approximant = IMRPhenomPv2
waveform_duration = 8
minimum_frequency = 20
reference_frequency = 50
coalescence_time = 6

# training parameters
kernel_length = 1.5
batch_size = 512
prior = priors.priors.end_o3_ratesandpops

# data conditioning / preprocessing parameters

# keep empty to use the default
fftlength = 
sample_rate = 2048
fduration = 1
highpass = 32

# inference / export parameters  
inference_psd_length = 64
inference_sampling_rate = 4
inference_batch_size = 128

[luigi_FetchTest]
workflow = htcondor
start = &::luigi_base::train_stop
end = &::luigi_base::test_stop
sample_rate = &::luigi_base::sample_rate
min_duration = 128
max_duration = &::luigi_base::max_duration
flag = &::luigi_base::flag
channels = &::luigi_base::channels
request_memory = 6GB
request_disk = 200MB
request_cpus = 1

[luigi_TestingWaveforms]
workflow = htcondor
num_signals = 100000
shifts = &::luigi_base::shifts
spacing = 16
buffer = 16
snr_threshold = 4
seed = &::luigi_base::seed
prior = &::luigi_base::prior
start = &::luigi_base::train_stop
end = &::luigi_base::test_stop
ifos = &::luigi_base::ifos
psd_length = &::luigi_base::inference_psd_length
sample_rate = &::luigi_base::sample_rate
minimum_frequency = &::luigi_base::minimum_frequency
reference_frequency = &::luigi_base::reference_frequency
waveform_duration = &::luigi_base::waveform_duration
waveform_approximant = &::luigi_base::waveform_approximant
coalescence_time = &::luigi_base::coalescence_time
highpass = &::luigi_base::highpass
request_memory = 6GB
request_disk = 200MB
request_cpus = 1

[luigi_ExportLocal]
fftlength = &::luigi_base::fftlength
fduration = &::luigi_base::fduration
kernel_length = &::luigi_base::kernel_length
inference_sampling_rate = &::luigi_base::inference_sampling_rate
sample_rate = &::luigi_base::sample_rate
platform = TENSORRT
ifos = &::luigi_base::ifos
batch_size = &::luigi_base::inference_batch_size
psd_length = &::luigi_base::inference_psd_length
highpass = &::luigi_base::highpass

streams_per_gpu = &::luigi_base::streams_per_gpu
aframe_instances = 6
preproc_instances = 1
clean = true

[luigi_SandboxInfer]
workflow = htcondor
fduration = &::luigi_base::fduration
batch_size = &::luigi_base::inference_batch_size
psd_length = &::luigi_base::inference_psd_length
ifos = &::luigi_base::ifos
inference_sampling_rate = &::luigi_base::inference_sampling_rate
cluster_window_length = 8
integration_window_length = 1
Tb = &::luigi_base::Tb
shifts = &::luigi_base::shifts
streams_per_gpu = &::luigi_base::streams_per_gpu
rate_per_gpu = 70
zero_lag = true

# triton args
model_name = aframe-stream
model_version = -1
triton_image = hermes/tritonserver:23.01
sequence_id = 1001

request_memory = 6G
request_disk = 1G
request_cpus = 1

[luigi_SandboxSV]
mass_combos =  [[35, 35], [35, 20], [20, 20], [20,10]]
ifos = &::luigi_base::ifos
source_prior = &::luigi_base::prior

[logging]
law: INFO 
law.sandbox.base: INFO
law.patches: INFO
luigi-interface: INFO
law.workflow.base: INFO
